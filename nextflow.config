manifest {
    homePage = 'https://github.com/adigenova/nf-gene-fusions'
    description = 'Gene fusion caller'
    mainScript = 'main.nf'
    author = 'Alex Di Genova'
    version = '1.1'
    name = 'gene-fusions'
}


// Load job.conf for process tagging
includeConfig 'conf/jobs.conf'

// Load genomes.config list the available genome reference
//todo: define the list of available here.
//includeConfig 'conf/genomes.conf'


profiles {
  docker {
	docker.enabled = true
	process.container = 'iarcbioinfo/nf-gene-fusions:v1.1'
	}
  singularity {
   singularity.enabled = true
   process.container = 'iarcbioinfo/nf-gene-fusions:v1.1'
   singularity.autoMounts = true
 }
}


//additionals files for visualization of arriba results
params {

//default arriba lib location from the container
arriba_lib='/opt/conda/envs/gene-fusions/var/lib/arriba'
arriba_opt = false
arriba_plot = true
arriba_svs = false
// Options: Building STAR-star_index
star_index = false
fasta = false
gtf   = false

read_length = 100

//Defaults for read data
reads = null
bams = null
reads_csv = null
svs = null
debug = false

help = false
// Shared default variables across different scripts
outdir = './results'
tracedir = "${params.outdir}/nf-pipeline_info"
ref_fa = null
ref_gtf = null

// Defaults
max_memory = 128.GB
max_cpus = 8
max_time = 240.h

//activate debug mode
debug = false

}

// Define timestamp, to avoid overwriting existing trace
def timestamp = new java.util.Date().format('yyyy-MM-dd_HH-mm-ss')

// nextflow run information
timeline {
  enabled = true
  file = "${params.tracedir}/${manifest.name}_${timestamp}_timeline.html"
}

report {
  enabled = true
  file = "${params.tracedir}/${manifest.name}_${timestamp}_report.html"
}

trace {
  enabled = true
  file = "${params.tracedir}/${manifest.name}_${timestamp}_trace.txt"
}

dag {
  enabled = true
  file = "${params.tracedir}/${manifest.name}_${timestamp}_dag.html"
}

//Mesage regarding errors or complete
workflow.onComplete = {
    // any workflow property can be used here
    println "Pipeline complete"
    println "Command line: $workflow.commandLine"
}


workflow.onError = {
   println "Oops... Pipeline execution stopped with the following message: ${workflow.errorMessage}"
}




// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
